{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW, without stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "dataset = pd.read_csv('dataset.csv')\n",
    "\n",
    "train_set, temp_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "test_set, val_set = train_test_split(temp_set, test_size=0.5, random_state=42)\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "X_train = vectorizer.fit_transform(train_set['text'])\n",
    "X_test = vectorizer.transform(test_set['text'])\n",
    "X_val = vectorizer.transform(val_set['text'])\n",
    "y_train = train_set['humor']\n",
    "y_test = test_set['humor']\n",
    "y_val = val_set['humor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.93215\n",
      "Naive Bayes Accuracy: 0.91575\n",
      "SGD Classifier Accuracy: 0.92655\n",
      "Ridge Classifier Accuracy: 0.92865\n",
      "\n",
      "Logistic Regression Precision: 0.9347651545564031\n",
      "Naive Bayes Precision: 0.899386738213875\n",
      "SGD Classifier Precision: 0.9312222670431626\n",
      "Ridge Classifier Precision: 0.9314257028112449\n",
      "\n",
      "Logistic Regression Recall: 0.9294481588663805\n",
      "Naive Bayes Recall: 0.9366330705518411\n",
      "SGD Classifier Recall: 0.9214649236603133\n",
      "Ridge Classifier Recall: 0.9257559125835745\n",
      "\n",
      "Logistic Regression F1-Score: 0.9320990743057292\n",
      "Naive Bayes F1-Score: 0.9176321063694579\n",
      "SGD Classifier F1-Score: 0.9263179013893765\n",
      "Ridge Classifier F1-Score: 0.9285821530453932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "logreg_model = LogisticRegression(max_iter=10000, solver='lbfgs')\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "naive_bayes_model = MultinomialNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "\n",
    "sgd_model = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "ridge_model = RidgeClassifier()\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "logreg_preds = logreg_model.predict(X_val)\n",
    "naive_bayes_preds = naive_bayes_model.predict(X_val)\n",
    "sgd_preds = sgd_model.predict(X_val)\n",
    "ridge_preds = ridge_model.predict(X_val)\n",
    "\n",
    "logreg_accuracy = accuracy_score(y_val, logreg_preds)\n",
    "naive_bayes_accuracy = accuracy_score(y_val, naive_bayes_preds)\n",
    "sgd_accuracy = accuracy_score(y_val, sgd_preds)\n",
    "ridge_accuracy = accuracy_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Accuracy: {logreg_accuracy}\")\n",
    "print(f\"Naive Bayes Accuracy: {naive_bayes_accuracy}\")\n",
    "print(f\"SGD Classifier Accuracy: {sgd_accuracy}\")\n",
    "print(f\"Ridge Classifier Accuracy: {ridge_accuracy}\\n\")\n",
    "\n",
    "# Calculate and print precision, recall, and F1-score for each model\n",
    "logreg_precision = precision_score(y_val, logreg_preds)\n",
    "naive_bayes_precision = precision_score(y_val, naive_bayes_preds)\n",
    "sgd_precision = precision_score(y_val, sgd_preds)\n",
    "ridge_precision = precision_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Precision: {logreg_precision}\")\n",
    "print(f\"Naive Bayes Precision: {naive_bayes_precision}\")\n",
    "print(f\"SGD Classifier Precision: {sgd_precision}\")\n",
    "print(f\"Ridge Classifier Precision: {ridge_precision}\\n\")\n",
    "\n",
    "logreg_recall = recall_score(y_val, logreg_preds)\n",
    "naive_bayes_recall = recall_score(y_val, naive_bayes_preds)\n",
    "sgd_recall = recall_score(y_val, sgd_preds)\n",
    "ridge_recall = recall_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Recall: {logreg_recall}\")\n",
    "print(f\"Naive Bayes Recall: {naive_bayes_recall}\")\n",
    "print(f\"SGD Classifier Recall: {sgd_recall}\")\n",
    "print(f\"Ridge Classifier Recall: {ridge_recall}\\n\")\n",
    "\n",
    "logreg_f1_score = f1_score(y_val, logreg_preds)\n",
    "naive_bayes_f1_score = f1_score(y_val, naive_bayes_preds)\n",
    "sgd_f1_score = f1_score(y_val, sgd_preds)\n",
    "ridge_f1_score = f1_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression F1-Score: {logreg_f1_score}\")\n",
    "print(f\"Naive Bayes F1-Score: {naive_bayes_f1_score}\")\n",
    "print(f\"SGD Classifier F1-Score: {sgd_f1_score}\")\n",
    "print(f\"Ridge Classifier F1-Score: {ridge_f1_score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ BOW, without stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with RBF Kernel Accuracy: 0.9408\n",
      "SGD Classifier Precision: 0.9312222670431626\n",
      "SGD Classifier Recall: 0.9391278315537371\n",
      "SGD Classifier F1-Score: 0.940817754673598\n"
     ]
    }
   ],
   "source": [
    "# Train a SVC model with RBF kernel\n",
    "svc_model = SVC(kernel='rbf')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_preds = svc_model.predict(X_val)\n",
    "\n",
    "svc_accuracy = accuracy_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Accuracy: {svc_accuracy}\")\n",
    "\n",
    "svc_precision = precision_score(y_val, svc_preds)\n",
    "print(f\"SGD Classifier Precision: {sgd_precision}\")\n",
    "\n",
    "svc_recall = recall_score(y_val, svc_preds)\n",
    "print(f\"SGD Classifier Recall: {svc_recall}\")\n",
    "\n",
    "svc_f1_score = f1_score(y_val, svc_preds)\n",
    "print(f\"SGD Classifier F1-Score: {svc_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ BOW, without stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with linear kernel Accuracy: 0.9284\n",
      "SVC with linear kernel Precision: 0.9289781240635301\n",
      "SVC with linear kernel Recall: 0.9280510927053188\n",
      "SVC with linear kernel F1-Score: 0.9285143769968051\n"
     ]
    }
   ],
   "source": [
    "# Train a SVC model with RBF kernel\n",
    "svc_model = SVC(kernel='linear')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_preds = svc_model.predict(X_val)\n",
    "\n",
    "svc_accuracy = accuracy_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Accuracy: {svc_accuracy}\")\n",
    "\n",
    "svc_precision = precision_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Precision: {svc_precision}\")\n",
    "\n",
    "svc_recall = recall_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Recall: {svc_recall}\")\n",
    "\n",
    "svc_f1_score = f1_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel F1-Score: {svc_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ BOW, without stop word removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF, without stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Split the dataset into training, testing, and validation sets\n",
    "train_set, temp_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "test_set, val_set = train_test_split(temp_set, test_size=0.5, random_state=42)\n",
    "\n",
    "# Vectorize the text data using Bag-of-Words (BoW) with a size of 10,000\n",
    "vectorizer = TfidfVectorizer(max_features=10_000)\n",
    "X_train = vectorizer.fit_transform(train_set['text'])\n",
    "X_test = vectorizer.transform(test_set['text'])\n",
    "X_val = vectorizer.transform(val_set['text'])\n",
    "y_train = train_set['humor']\n",
    "y_test = test_set['humor']\n",
    "y_val = val_set['humor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9275\n",
      "Naive Bayes Accuracy: 0.9118\n",
      "SGD Classifier Accuracy: 0.91385\n",
      "Ridge Classifier Accuracy: 0.9277\n",
      "\n",
      "Logistic Regression Precision: 0.9285928592859286\n",
      "Naive Bayes Precision: 0.8976211114321487\n",
      "SGD Classifier Precision: 0.916148445336008\n",
      "Ridge Classifier Precision: 0.926829268292683\n",
      "\n",
      "Logistic Regression Recall: 0.9265542361041812\n",
      "Naive Bayes Recall: 0.9300469015068357\n",
      "SGD Classifier Recall: 0.9114858796527293\n",
      "Ridge Classifier Recall: 0.9290489971060772\n",
      "\n",
      "Logistic Regression F1-Score: 0.9275724275724276\n",
      "Naive Bayes F1-Score: 0.9135463634581454\n",
      "SGD Classifier F1-Score: 0.913811215046771\n",
      "Ridge Classifier F1-Score: 0.9279378052426991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "logreg_model = LogisticRegression(max_iter=10_000, solver='lbfgs')\n",
    "logreg_model.fit(X_train, y_train)\n",
    "naive_bayes_model = MultinomialNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "sgd_model = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "ridge_model = RidgeClassifier()\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "logreg_preds = logreg_model.predict(X_val)\n",
    "naive_bayes_preds = naive_bayes_model.predict(X_val)\n",
    "sgd_preds = sgd_model.predict(X_val)\n",
    "ridge_preds = ridge_model.predict(X_val)\n",
    "\n",
    "logreg_accuracy = accuracy_score(y_val, logreg_preds)\n",
    "naive_bayes_accuracy = accuracy_score(y_val, naive_bayes_preds)\n",
    "sgd_accuracy = accuracy_score(y_val, sgd_preds)\n",
    "ridge_accuracy = accuracy_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Accuracy: {logreg_accuracy}\")\n",
    "print(f\"Naive Bayes Accuracy: {naive_bayes_accuracy}\")\n",
    "print(f\"SGD Classifier Accuracy: {sgd_accuracy}\")\n",
    "print(f\"Ridge Classifier Accuracy: {ridge_accuracy}\\n\")\n",
    "\n",
    "logreg_precision = precision_score(y_val, logreg_preds)\n",
    "naive_bayes_precision = precision_score(y_val, naive_bayes_preds)\n",
    "sgd_precision = precision_score(y_val, sgd_preds)\n",
    "ridge_precision = precision_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Precision: {logreg_precision}\")\n",
    "print(f\"Naive Bayes Precision: {naive_bayes_precision}\")\n",
    "print(f\"SGD Classifier Precision: {sgd_precision}\")\n",
    "print(f\"Ridge Classifier Precision: {ridge_precision}\\n\")\n",
    "\n",
    "logreg_recall = recall_score(y_val, logreg_preds)\n",
    "naive_bayes_recall = recall_score(y_val, naive_bayes_preds)\n",
    "sgd_recall = recall_score(y_val, sgd_preds)\n",
    "ridge_recall = recall_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Recall: {logreg_recall}\")\n",
    "print(f\"Naive Bayes Recall: {naive_bayes_recall}\")\n",
    "print(f\"SGD Classifier Recall: {sgd_recall}\")\n",
    "print(f\"Ridge Classifier Recall: {ridge_recall}\\n\")\n",
    "\n",
    "logreg_f1_score = f1_score(y_val, logreg_preds)\n",
    "naive_bayes_f1_score = f1_score(y_val, naive_bayes_preds)\n",
    "sgd_f1_score = f1_score(y_val, sgd_preds)\n",
    "ridge_f1_score = f1_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression F1-Score: {logreg_f1_score}\")\n",
    "print(f\"Naive Bayes F1-Score: {naive_bayes_f1_score}\")\n",
    "print(f\"SGD Classifier F1-Score: {sgd_f1_score}\")\n",
    "print(f\"Ridge Classifier F1-Score: {ridge_f1_score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ TF-IDF, without stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with RBF Kernel Accuracy: 0.9398\n",
      "SVC with RBF Kernel Precision: 0.9390498954287422\n",
      "SVC with RBF Kernel Recall: 0.9409240594751023\n",
      "SVC with RBF Kernel F1-Score: 0.9399860432658758\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel='rbf')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_preds = svc_model.predict(X_val)\n",
    "\n",
    "svc_accuracy = accuracy_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Accuracy: {svc_accuracy}\")\n",
    "\n",
    "svc_precision = precision_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Precision: {svc_precision}\")\n",
    "\n",
    "svc_recall = recall_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Recall: {svc_recall}\")\n",
    "\n",
    "svc_f1_score = f1_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel F1-Score: {svc_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ TF-IDF, without stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with linear kernel Accuracy: 0.92775\n",
      "SVC with linear kernel Precision: 0.9260731319554849\n",
      "SVC with linear kernel Recall: 0.9300469015068357\n",
      "SVC with linear kernel F1-Score: 0.9280557630072193\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel='linear')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_preds = svc_model.predict(X_val)\n",
    "\n",
    "svc_accuracy = accuracy_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Accuracy: {svc_accuracy}\")\n",
    "\n",
    "svc_precision = precision_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Precision: {svc_precision}\")\n",
    "\n",
    "svc_recall = recall_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Recall: {svc_recall}\")\n",
    "\n",
    "svc_f1_score = f1_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel F1-Score: {svc_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ TF-IDF, without stop word removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW, with stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "dataset = pd.read_csv('dataset.csv')\n",
    "\n",
    "train_set, temp_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "test_set, val_set = train_test_split(temp_set, test_size=0.5, random_state=42)\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=10_000, stop_words='english')\n",
    "X_train = vectorizer.fit_transform(train_set['text'])\n",
    "X_test = vectorizer.transform(test_set['text'])\n",
    "X_val = vectorizer.transform(val_set['text'])\n",
    "y_train = train_set['humor']\n",
    "y_test = test_set['humor']\n",
    "y_val = val_set['humor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8961\n",
      "Naive Bayes Accuracy: 0.88895\n",
      "SGD Classifier Accuracy: 0.8913\n",
      "Ridge Classifier Accuracy: 0.89245\n",
      "\n",
      "Logistic Regression Precision: 0.8924019365675329\n",
      "Naive Bayes Precision: 0.884387936132466\n",
      "SGD Classifier Precision: 0.8862853204686423\n",
      "Ridge Classifier Precision: 0.8840523130977943\n",
      "\n",
      "Logistic Regression Recall: 0.9013072547649935\n",
      "Naive Bayes Recall: 0.8954196188005189\n",
      "SGD Classifier Recall: 0.8983135415627183\n",
      "Ridge Classifier Recall: 0.9039018062069654\n",
      "\n",
      "Logistic Regression F1-Score: 0.8968324893257869\n",
      "Naive Bayes F1-Score: 0.8898695889324144\n",
      "SGD Classifier F1-Score: 0.8922588958271385\n",
      "Ridge Classifier F1-Score: 0.8938668771895198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "logreg_model = LogisticRegression(max_iter=10_000, solver='lbfgs')\n",
    "logreg_model.fit(X_train, y_train)\n",
    "naive_bayes_model = MultinomialNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "sgd_model = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "ridge_model = RidgeClassifier()\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "logreg_preds = logreg_model.predict(X_val)\n",
    "naive_bayes_preds = naive_bayes_model.predict(X_val)\n",
    "sgd_preds = sgd_model.predict(X_val)\n",
    "ridge_preds = ridge_model.predict(X_val)\n",
    "\n",
    "logreg_accuracy = accuracy_score(y_val, logreg_preds)\n",
    "naive_bayes_accuracy = accuracy_score(y_val, naive_bayes_preds)\n",
    "sgd_accuracy = accuracy_score(y_val, sgd_preds)\n",
    "ridge_accuracy = accuracy_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Accuracy: {logreg_accuracy}\")\n",
    "print(f\"Naive Bayes Accuracy: {naive_bayes_accuracy}\")\n",
    "print(f\"SGD Classifier Accuracy: {sgd_accuracy}\")\n",
    "print(f\"Ridge Classifier Accuracy: {ridge_accuracy}\\n\")\n",
    "\n",
    "logreg_precision = precision_score(y_val, logreg_preds)\n",
    "naive_bayes_precision = precision_score(y_val, naive_bayes_preds)\n",
    "sgd_precision = precision_score(y_val, sgd_preds)\n",
    "ridge_precision = precision_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Precision: {logreg_precision}\")\n",
    "print(f\"Naive Bayes Precision: {naive_bayes_precision}\")\n",
    "print(f\"SGD Classifier Precision: {sgd_precision}\")\n",
    "print(f\"Ridge Classifier Precision: {ridge_precision}\\n\")\n",
    "\n",
    "logreg_recall = recall_score(y_val, logreg_preds)\n",
    "naive_bayes_recall = recall_score(y_val, naive_bayes_preds)\n",
    "sgd_recall = recall_score(y_val, sgd_preds)\n",
    "ridge_recall = recall_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Recall: {logreg_recall}\")\n",
    "print(f\"Naive Bayes Recall: {naive_bayes_recall}\")\n",
    "print(f\"SGD Classifier Recall: {sgd_recall}\")\n",
    "print(f\"Ridge Classifier Recall: {ridge_recall}\\n\")\n",
    "\n",
    "logreg_f1_score = f1_score(y_val, logreg_preds)\n",
    "naive_bayes_f1_score = f1_score(y_val, naive_bayes_preds)\n",
    "sgd_f1_score = f1_score(y_val, sgd_preds)\n",
    "ridge_f1_score = f1_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression F1-Score: {logreg_f1_score}\")\n",
    "print(f\"Naive Bayes F1-Score: {naive_bayes_f1_score}\")\n",
    "print(f\"SGD Classifier F1-Score: {sgd_f1_score}\")\n",
    "print(f\"Ridge Classifier F1-Score: {ridge_f1_score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ BOW, with stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with RBF Kernel Accuracy: 0.9054\n",
      "SVC with RBF Kernel Precision: 0.9013528191962081\n",
      "SVC with RBF Kernel Recall: 0.9108871370122742\n",
      "SVC with RBF Kernel F1-Score: 0.9060948977566011\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel='rbf')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_preds = svc_model.predict(X_val)\n",
    "\n",
    "svc_accuracy = accuracy_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Accuracy: {svc_accuracy}\")\n",
    "\n",
    "svc_precision = precision_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Precision: {svc_precision}\")\n",
    "\n",
    "svc_recall = recall_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Recall: {svc_recall}\")\n",
    "\n",
    "svc_f1_score = f1_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel F1-Score: {svc_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ BOW, with stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with linear kernel Accuracy: 0.89385\n",
      "SVC with linear kernel Precision: 0.8882989183874139\n",
      "SVC with linear kernel Recall: 0.9015068356451452\n",
      "SVC with linear kernel F1-Score: 0.894854142934971\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel='linear')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_preds = svc_model.predict(X_val)\n",
    "\n",
    "svc_accuracy = accuracy_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Accuracy: {svc_accuracy}\")\n",
    "\n",
    "svc_precision = precision_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Precision: {svc_precision}\")\n",
    "\n",
    "svc_recall = recall_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Recall: {svc_recall}\")\n",
    "\n",
    "svc_f1_score = f1_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel F1-Score: {svc_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ BOW, with stop word removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF, with stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Split the dataset into training, testing, and validation sets\n",
    "train_set, temp_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "test_set, val_set = train_test_split(temp_set, test_size=0.5, random_state=42)\n",
    "\n",
    "# Vectorize the text data using Bag-of-Words (BoW) with a size of 10,000\n",
    "vectorizer = TfidfVectorizer(max_features=10_000, stop_words='english')\n",
    "X_train = vectorizer.fit_transform(train_set['text'])\n",
    "X_test = vectorizer.transform(test_set['text'])\n",
    "X_val = vectorizer.transform(val_set['text'])\n",
    "y_train = train_set['humor']\n",
    "y_test = test_set['humor']\n",
    "y_val = val_set['humor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8938\n",
      "Naive Bayes Accuracy: 0.887\n",
      "SGD Classifier Accuracy: 0.88435\n",
      "Ridge Classifier Accuracy: 0.8942\n",
      "\n",
      "Logistic Regression Precision: 0.8941798941798942\n",
      "Naive Bayes Precision: 0.8872368027142999\n",
      "SGD Classifier Precision: 0.8893715902202465\n",
      "Ridge Classifier Precision: 0.8909108891306498\n",
      "\n",
      "Logistic Regression Recall: 0.8938229717593055\n",
      "Naive Bayes Recall: 0.8872368027142999\n",
      "SGD Classifier Recall: 0.878455243987626\n",
      "Ridge Classifier Recall: 0.8989122842031734\n",
      "\n",
      "Logistic Regression F1-Score: 0.8940013973450445\n",
      "Naive Bayes F1-Score: 0.8872368027142999\n",
      "SGD Classifier F1-Score: 0.8838797128369897\n",
      "Ridge Classifier F1-Score: 0.8948937015696404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "logreg_model = LogisticRegression(max_iter=10_000, solver='lbfgs')\n",
    "logreg_model.fit(X_train, y_train)\n",
    "naive_bayes_model = MultinomialNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "sgd_model = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "ridge_model = RidgeClassifier()\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "logreg_preds = logreg_model.predict(X_val)\n",
    "naive_bayes_preds = naive_bayes_model.predict(X_val)\n",
    "sgd_preds = sgd_model.predict(X_val)\n",
    "ridge_preds = ridge_model.predict(X_val)\n",
    "\n",
    "logreg_accuracy = accuracy_score(y_val, logreg_preds)\n",
    "naive_bayes_accuracy = accuracy_score(y_val, naive_bayes_preds)\n",
    "sgd_accuracy = accuracy_score(y_val, sgd_preds)\n",
    "ridge_accuracy = accuracy_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Accuracy: {logreg_accuracy}\")\n",
    "print(f\"Naive Bayes Accuracy: {naive_bayes_accuracy}\")\n",
    "print(f\"SGD Classifier Accuracy: {sgd_accuracy}\")\n",
    "print(f\"Ridge Classifier Accuracy: {ridge_accuracy}\\n\")\n",
    "\n",
    "logreg_precision = precision_score(y_val, logreg_preds)\n",
    "naive_bayes_precision = precision_score(y_val, naive_bayes_preds)\n",
    "sgd_precision = precision_score(y_val, sgd_preds)\n",
    "ridge_precision = precision_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Precision: {logreg_precision}\")\n",
    "print(f\"Naive Bayes Precision: {naive_bayes_precision}\")\n",
    "print(f\"SGD Classifier Precision: {sgd_precision}\")\n",
    "print(f\"Ridge Classifier Precision: {ridge_precision}\\n\")\n",
    "\n",
    "logreg_recall = recall_score(y_val, logreg_preds)\n",
    "naive_bayes_recall = recall_score(y_val, naive_bayes_preds)\n",
    "sgd_recall = recall_score(y_val, sgd_preds)\n",
    "ridge_recall = recall_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Recall: {logreg_recall}\")\n",
    "print(f\"Naive Bayes Recall: {naive_bayes_recall}\")\n",
    "print(f\"SGD Classifier Recall: {sgd_recall}\")\n",
    "print(f\"Ridge Classifier Recall: {ridge_recall}\\n\")\n",
    "\n",
    "logreg_f1_score = f1_score(y_val, logreg_preds)\n",
    "naive_bayes_f1_score = f1_score(y_val, naive_bayes_preds)\n",
    "sgd_f1_score = f1_score(y_val, sgd_preds)\n",
    "ridge_f1_score = f1_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression F1-Score: {logreg_f1_score}\")\n",
    "print(f\"Naive Bayes F1-Score: {naive_bayes_f1_score}\")\n",
    "print(f\"SGD Classifier F1-Score: {sgd_f1_score}\")\n",
    "print(f\"Ridge Classifier F1-Score: {ridge_f1_score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ TF-IDF, with stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with RBF Kernel Accuracy: 0.9071\n",
      "SVC with RBF Kernel Precision: 0.9064834179862563\n",
      "SVC with RBF Kernel Recall: 0.9082925855703023\n",
      "SVC with RBF Kernel F1-Score: 0.9073870999900308\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel='rbf')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_preds = svc_model.predict(X_val)\n",
    "\n",
    "svc_accuracy = accuracy_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Accuracy: {svc_accuracy}\")\n",
    "\n",
    "svc_precision = precision_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Precision: {svc_precision}\")\n",
    "\n",
    "svc_recall = recall_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Recall: {svc_recall}\")\n",
    "\n",
    "svc_f1_score = f1_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel F1-Score: {svc_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ TF-IDF, with stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with linear kernel Accuracy: 0.8962\n",
      "SVC with linear kernel Precision: 0.8932778932778933\n",
      "SVC with linear kernel Recall: 0.9004091408043109\n",
      "SVC with linear kernel F1-Score: 0.8968293410197793\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel='linear')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_preds = svc_model.predict(X_val)\n",
    "\n",
    "svc_accuracy = accuracy_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Accuracy: {svc_accuracy}\")\n",
    "\n",
    "svc_precision = precision_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Precision: {svc_precision}\")\n",
    "\n",
    "svc_recall = recall_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Recall: {svc_recall}\")\n",
    "\n",
    "svc_f1_score = f1_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel F1-Score: {svc_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ TF-IDF, with stop word removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW, with POS-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\compat.py:36: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  hasattr(torch, \"has_mps\")\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\compat.py:37: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  and torch.has_mps  # type: ignore[attr-defined]\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "global counter\n",
    "counter = 0\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    word_unigrams, pos_unigrams = [], []\n",
    "    for i, token in enumerate(doc):\n",
    "        word_unigrams.append(token.text)\n",
    "        pos_unigrams.append(token.tag_)\n",
    "        \n",
    "    combined_n_grams = word_unigrams + pos_unigrams\n",
    "    return combined_n_grams\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Split the dataset into training, testing, and validation sets\n",
    "train_set, temp_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "test_set, val_set = train_test_split(temp_set, test_size=0.5, random_state=42)\n",
    "\n",
    "# Vectorize the text data using Bag-of-Words (BoW) with a size of 10,000\n",
    "vectorizer = CountVectorizer(max_features=10_000, tokenizer=tokenize)\n",
    "X_train = vectorizer.fit_transform(train_set['text'])\n",
    "X_test = vectorizer.transform(test_set['text'])\n",
    "X_val = vectorizer.transform(val_set['text'])\n",
    "y_train = train_set['humor']\n",
    "y_test = test_set['humor']\n",
    "y_val = val_set['humor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.967\n",
      "Naive Bayes Accuracy: 0.93905\n",
      "SGD Classifier Accuracy: 0.96325\n",
      "Ridge Classifier Accuracy: 0.9632\n",
      "\n",
      "Logistic Regression Precision: 0.9700713066184594\n",
      "Naive Bayes Precision: 0.9154238248064942\n",
      "SGD Classifier Precision: 0.9581606473258338\n",
      "Ridge Classifier Precision: 0.9720386375190646\n",
      "\n",
      "Logistic Regression Recall: 0.9638758606925456\n",
      "Naive Bayes Recall: 0.9677676878555035\n",
      "SGD Classifier Recall: 0.9689651731364135\n",
      "Ridge Classifier Recall: 0.9539966071250374\n",
      "\n",
      "Logistic Regression F1-Score: 0.9669636600260286\n",
      "Naive Bayes F1-Score: 0.9408682997817123\n",
      "SGD Classifier F1-Score: 0.9635326221781195\n",
      "Ridge Classifier F1-Score: 0.9629331184528606\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "logreg_model = LogisticRegression(max_iter=10000, solver='lbfgs')\n",
    "logreg_model.fit(X_train, y_train)\n",
    "naive_bayes_model = MultinomialNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "sgd_model = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "ridge_model = RidgeClassifier()\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "logreg_preds = logreg_model.predict(X_val)\n",
    "naive_bayes_preds = naive_bayes_model.predict(X_val)\n",
    "sgd_preds = sgd_model.predict(X_val)\n",
    "ridge_preds = ridge_model.predict(X_val)\n",
    "\n",
    "logreg_accuracy = accuracy_score(y_val, logreg_preds)\n",
    "naive_bayes_accuracy = accuracy_score(y_val, naive_bayes_preds)\n",
    "sgd_accuracy = accuracy_score(y_val, sgd_preds)\n",
    "ridge_accuracy = accuracy_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Accuracy: {logreg_accuracy}\")\n",
    "print(f\"Naive Bayes Accuracy: {naive_bayes_accuracy}\")\n",
    "print(f\"SGD Classifier Accuracy: {sgd_accuracy}\")\n",
    "print(f\"Ridge Classifier Accuracy: {ridge_accuracy}\\n\")\n",
    "\n",
    "logreg_precision = precision_score(y_val, logreg_preds)\n",
    "naive_bayes_precision = precision_score(y_val, naive_bayes_preds)\n",
    "sgd_precision = precision_score(y_val, sgd_preds)\n",
    "ridge_precision = precision_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Precision: {logreg_precision}\")\n",
    "print(f\"Naive Bayes Precision: {naive_bayes_precision}\")\n",
    "print(f\"SGD Classifier Precision: {sgd_precision}\")\n",
    "print(f\"Ridge Classifier Precision: {ridge_precision}\\n\")\n",
    "\n",
    "logreg_recall = recall_score(y_val, logreg_preds)\n",
    "naive_bayes_recall = recall_score(y_val, naive_bayes_preds)\n",
    "sgd_recall = recall_score(y_val, sgd_preds)\n",
    "ridge_recall = recall_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Recall: {logreg_recall}\")\n",
    "print(f\"Naive Bayes Recall: {naive_bayes_recall}\")\n",
    "print(f\"SGD Classifier Recall: {sgd_recall}\")\n",
    "print(f\"Ridge Classifier Recall: {ridge_recall}\\n\")\n",
    "\n",
    "logreg_f1_score = f1_score(y_val, logreg_preds)\n",
    "naive_bayes_f1_score = f1_score(y_val, naive_bayes_preds)\n",
    "sgd_f1_score = f1_score(y_val, sgd_preds)\n",
    "ridge_f1_score = f1_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression F1-Score: {logreg_f1_score}\")\n",
    "print(f\"Naive Bayes F1-Score: {naive_bayes_f1_score}\")\n",
    "print(f\"SGD Classifier F1-Score: {sgd_f1_score}\")\n",
    "print(f\"Ridge Classifier F1-Score: {ridge_f1_score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ BOW, with POS-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with RBF Kernel Accuracy: 0.96995\n",
      "SVC with RBF Kernel Precision: 0.9722277922598757\n",
      "SVC with RBF Kernel Recall: 0.9676678974154276\n",
      "SVC with RBF Kernel F1-Score: 0.9699424856214053\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel='rbf')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_preds = svc_model.predict(X_val)\n",
    "\n",
    "svc_accuracy = accuracy_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Accuracy: {svc_accuracy}\")\n",
    "\n",
    "svc_precision = precision_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Precision: {svc_precision}\")\n",
    "\n",
    "svc_recall = recall_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Recall: {svc_recall}\")\n",
    "\n",
    "svc_f1_score = f1_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel F1-Score: {svc_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ BOW, with POS-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with linear kernel Accuracy: 0.9635\n",
      "SVC with linear kernel Precision: 0.9646894068220466\n",
      "SVC with linear kernel Recall: 0.9623790040914081\n",
      "SVC with linear kernel F1-Score: 0.9635328204615847\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel='linear')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_preds = svc_model.predict(X_val)\n",
    "\n",
    "svc_accuracy = accuracy_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Accuracy: {svc_accuracy}\")\n",
    "\n",
    "svc_precision = precision_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Precision: {svc_precision}\")\n",
    "\n",
    "svc_recall = recall_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Recall: {svc_recall}\")\n",
    "\n",
    "svc_f1_score = f1_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel F1-Score: {svc_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ BOW, with POS-tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\compat.py:36: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  hasattr(torch, \"has_mps\")\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\compat.py:37: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  and torch.has_mps  # type: ignore[attr-defined]\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Extract unigrams and bigrams in a single loop\n",
    "    word_unigrams, pos_unigrams, word_bigrams, pos_bigrams = [], [], [], []\n",
    "    for i, token in enumerate(doc):\n",
    "        word_unigrams.append(token.text)\n",
    "        pos_unigrams.append(token.tag_)\n",
    "        \n",
    "        if i < len(doc) - 1:\n",
    "            word_bigrams.append(token.text + '_' + doc[i + 1].text)\n",
    "            pos_bigrams.append(token.tag_ + '_' + doc[i + 1].tag_)\n",
    "    \n",
    "    # Combine all lists\n",
    "    combined_n_grams = word_unigrams + pos_unigrams + word_bigrams + pos_bigrams\n",
    "\n",
    "    return combined_n_grams\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Split the dataset into training, testing, and validation sets\n",
    "train_set, temp_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "test_set, val_set = train_test_split(temp_set, test_size=0.5, random_state=42)\n",
    "\n",
    "# Vectorize the text data using Bag-of-Words (BoW) with a size of 10,000\n",
    "vectorizer = CountVectorizer(max_features=10_000, tokenizer=tokenize)\n",
    "X_train = vectorizer.fit_transform(train_set['text'])\n",
    "X_test = vectorizer.transform(test_set['text'])\n",
    "X_val = vectorizer.transform(val_set['text'])\n",
    "y_train = train_set['humor']\n",
    "y_test = test_set['humor']\n",
    "y_val = val_set['humor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9742\n",
      "Naive Bayes Accuracy: 0.9406\n",
      "\n",
      "Logistic Regression Precision: 0.9784556528742575\n",
      "Naive Bayes Precision: 0.9229148712055922\n",
      "\n",
      "Logistic Regression Recall: 0.9698632870970961\n",
      "Naive Bayes Recall: 0.961780261450953\n",
      "\n",
      "Logistic Regression F1-Score: 0.9741405232033677\n",
      "Naive Bayes F1-Score: 0.9419468334636435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "logreg_model = LogisticRegression(solver='lbfgs', max_iter=1_000_000)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "naive_bayes_model = MultinomialNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "\n",
    "logreg_preds = logreg_model.predict(X_val)\n",
    "naive_bayes_preds = naive_bayes_model.predict(X_val)\n",
    "\n",
    "logreg_accuracy = accuracy_score(y_val, logreg_preds)\n",
    "naive_bayes_accuracy = accuracy_score(y_val, naive_bayes_preds)\n",
    "print(f\"Logistic Regression Accuracy: {logreg_accuracy}\")\n",
    "print(f\"Naive Bayes Accuracy: {naive_bayes_accuracy}\\n\")\n",
    "\n",
    "logreg_precision = precision_score(y_val, logreg_preds)\n",
    "naive_bayes_precision = precision_score(y_val, naive_bayes_preds)\n",
    "print(f\"Logistic Regression Precision: {logreg_precision}\")\n",
    "print(f\"Naive Bayes Precision: {naive_bayes_precision}\\n\")\n",
    "\n",
    "logreg_recall = recall_score(y_val, logreg_preds)\n",
    "naive_bayes_recall = recall_score(y_val, naive_bayes_preds)\n",
    "print(f\"Logistic Regression Recall: {logreg_recall}\")\n",
    "print(f\"Naive Bayes Recall: {naive_bayes_recall}\\n\")\n",
    "\n",
    "logreg_f1_score = f1_score(y_val, logreg_preds)\n",
    "naive_bayes_f1_score = f1_score(y_val, naive_bayes_preds)\n",
    "print(f\"Logistic Regression F1-Score: {logreg_f1_score}\")\n",
    "print(f\"Naive Bayes F1-Score: {naive_bayes_f1_score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD = 0.97045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.93975\n",
      "Ensemble Precision: 0.910581222056632\n",
      "Ensemble Recall: 0.975551342181419\n",
      "Ensemble F1-Score: 0.9419472948884715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "logreg_model = LogisticRegression(solver='lbfgs', max_iter=1_000)\n",
    "rbf_svc_model = SVC(kernel='rbf', probability=True, max_iter=1_000)\n",
    "linear_svc_model = SVC(kernel='linear', probability=True, max_iter=1_000)\n",
    "#ridge_model = RidgeClassifier()\n",
    "\n",
    "# Create the ensemble classifier\n",
    "ensemble_classifier = VotingClassifier(estimators=[\n",
    "    ('logistic_regression', logreg_model),\n",
    "    ('rbf_support_vector_classifier', rbf_svc_model),\n",
    "\t('linear_support_vector_classifier', linear_svc_model),\n",
    "\t#('ridge_classifier', ridge_model)\n",
    "], voting='soft')  # You can use 'hard' or 'soft' voting, depending on your preference\n",
    "\n",
    "# Fit the ensemble model on the training data\n",
    "ensemble_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the ensemble model\n",
    "ensemble_preds = ensemble_classifier.predict(X_val)\n",
    "\n",
    "ensemble_accuracy = accuracy_score(y_val, ensemble_preds)\n",
    "print(f\"Ensemble Accuracy: {ensemble_accuracy}\")\n",
    "\n",
    "ensemble_precision = precision_score(y_val, ensemble_preds)\n",
    "print(f\"Ensemble Precision: {ensemble_precision}\")\n",
    "\n",
    "ensemble_recall = recall_score(y_val, ensemble_preds)\n",
    "print(f\"Ensemble Recall: {ensemble_recall}\")\n",
    "\n",
    "ensemble_f1_score = f1_score(y_val, ensemble_preds)\n",
    "print(f\"Ensemble F1-Score: {ensemble_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Ensemble Accuracy with Logistic Regression as Final Estimator: 0.9741\n",
      "Stacked Precision: 0.9774896995276856\n",
      "Stacked Recall: 0.9706616106177028\n",
      "Stacked F1-Score: 0.9740636891648308\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define base classifiers\n",
    "logreg_model = LogisticRegression(solver='lbfgs', max_iter=1_000)\n",
    "rbf_svc_model = SVC(kernel='rbf', probability=True, max_iter=1_000)\n",
    "linear_svc_model = SVC(kernel='linear', probability=True, max_iter=1_000)\n",
    "#ridge_model = RidgeClassifier()\n",
    "\n",
    "# Define final (meta) classifier\n",
    "final_logreg_model = LogisticRegression(solver='lbfgs', max_iter=1_000)\n",
    "\n",
    "# Create the stacking classifier\n",
    "stacking_classifier = StackingClassifier(estimators=[\n",
    "    ('logistic_regression', logreg_model),\n",
    "    ('rbf_support_vector_classifier', rbf_svc_model),\n",
    "\t('linear_support_vector_classifier', linear_svc_model),\n",
    "], final_estimator=final_logreg_model)\n",
    "\n",
    "# Fit the stacking classifier\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the stacking classifier\n",
    "stacked_preds = stacking_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the stacking classifier\n",
    "stacked_accuracy = accuracy_score(y_val, stacked_preds)\n",
    "print(f\"Stacked Ensemble Accuracy with Logistic Regression as Final Estimator: {stacked_accuracy}\")\n",
    "\n",
    "stacked_precision = precision_score(y_val, stacked_preds)\n",
    "print(f\"Stacked Precision: {stacked_precision}\")\n",
    "\n",
    "stacked_recall = recall_score(y_val, stacked_preds)\n",
    "print(f\"Stacked Recall: {stacked_recall}\")\n",
    "\n",
    "stacked_f1_score = f1_score(y_val, stacked_preds)\n",
    "print(f\"Stacked F1-Score: {stacked_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with RBF Kernel Accuracy: 0.9717\n",
      "SVC with RBF Kernel Precision: 0.9755557790966704\n",
      "SVC with RBF Kernel Recall: 0.9677676878555035\n",
      "SVC with RBF Kernel F1-Score: 0.9716461276425209\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel='rbf')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_preds = svc_model.predict(X_val)\n",
    "\n",
    "svc_accuracy = accuracy_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Accuracy: {svc_accuracy}\")\n",
    "\n",
    "svc_precision = precision_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Precision: {svc_precision}\")\n",
    "\n",
    "svc_recall = recall_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Recall: {svc_recall}\")\n",
    "\n",
    "svc_f1_score = f1_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel F1-Score: {svc_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with linear kernel Accuracy: 0.97065\n",
      "SVC with linear kernel Precision: 0.9738798472975688\n",
      "SVC with linear kernel Recall: 0.9673685260952001\n",
      "SVC with linear kernel F1-Score: 0.970613266583229\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel='linear')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_preds = svc_model.predict(X_val)\n",
    "\n",
    "svc_accuracy = accuracy_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Accuracy: {svc_accuracy}\")\n",
    "\n",
    "svc_precision = precision_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Precision: {svc_precision}\")\n",
    "\n",
    "svc_recall = recall_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Recall: {svc_recall}\")\n",
    "\n",
    "svc_f1_score = f1_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel F1-Score: {svc_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC (linear) med max_iter=uendelig: 0.97065, 182min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    tokens = []\n",
    "    pos_tokens = []\n",
    "    for i, token in enumerate(doc):\n",
    "        tokens.append(token.text)\n",
    "        pos_tokens.append(token.tag_)\n",
    "\n",
    "        if i < len(doc) - 1:\n",
    "            tokens.append(token.text + '_' + doc[i + 1].text)\n",
    "            pos_tokens.append(token.tag_ + '_' + doc[i + 1].tag_)\n",
    "        if i < len(doc) - 2:\n",
    "            tokens.append(token.text + '_' + doc[i + 1].text + '_' + doc[i + 2].text)\n",
    "            pos_tokens.append(token.tag_ + '_' + doc[i + 1].tag_ + '_' + doc[i + 2].tag_)\n",
    "    \n",
    "    return tokens + pos_tokens\n",
    "\n",
    "dataset = pd.read_csv('dataset.csv')\n",
    "\n",
    "train_set, temp_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "test_set, val_set = train_test_split(temp_set, test_size=0.5, random_state=42)\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=20000, tokenizer=tokenize)\n",
    "X_train = vectorizer.fit_transform(train_set['text'])\n",
    "X_test = vectorizer.transform(test_set['text'])\n",
    "X_val = vectorizer.transform(val_set['text'])\n",
    "y_train = train_set['humor']\n",
    "y_test = test_set['humor']\n",
    "y_val = val_set['humor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.97385\n",
      "Naive Bayes Accuracy: 0.9396\n",
      "SGD Classifier Accuracy: 0.97155\n",
      "Ridge Classifier Accuracy: 0.9695\n",
      "\n",
      "Logistic Regression Precision: 0.9778627490440732\n",
      "Naive Bayes Precision: 0.9245592060892186\n",
      "SGD Classifier Precision: 0.9723166100339796\n",
      "Ridge Classifier Precision: 0.9778612775464609\n",
      "\n",
      "Logistic Regression Recall: 0.9697634966570202\n",
      "Naive Bayes Recall: 0.9575890629677677\n",
      "SGD Classifier Recall: 0.9708611914978545\n",
      "Ridge Classifier Recall: 0.9608821474902705\n",
      "\n",
      "Logistic Regression F1-Score: 0.9737962823788767\n",
      "Naive Bayes F1-Score: 0.9407843137254901\n",
      "SGD Classifier F1-Score: 0.9715883557197784\n",
      "Ridge Classifier F1-Score: 0.9692973625931147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "logreg_model = LogisticRegression(max_iter=10_000, solver='lbfgs')\n",
    "logreg_model.fit(X_train, y_train)\n",
    "naive_bayes_model = MultinomialNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "sgd_model = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "ridge_model = RidgeClassifier()\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "logreg_preds = logreg_model.predict(X_val)\n",
    "naive_bayes_preds = naive_bayes_model.predict(X_val)\n",
    "sgd_preds = sgd_model.predict(X_val)\n",
    "ridge_preds = ridge_model.predict(X_val)\n",
    "\n",
    "logreg_accuracy = accuracy_score(y_val, logreg_preds)\n",
    "naive_bayes_accuracy = accuracy_score(y_val, naive_bayes_preds)\n",
    "sgd_accuracy = accuracy_score(y_val, sgd_preds)\n",
    "ridge_accuracy = accuracy_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Accuracy: {logreg_accuracy}\")\n",
    "print(f\"Naive Bayes Accuracy: {naive_bayes_accuracy}\")\n",
    "print(f\"SGD Classifier Accuracy: {sgd_accuracy}\")\n",
    "print(f\"Ridge Classifier Accuracy: {ridge_accuracy}\\n\")\n",
    "\n",
    "logreg_precision = precision_score(y_val, logreg_preds)\n",
    "naive_bayes_precision = precision_score(y_val, naive_bayes_preds)\n",
    "sgd_precision = precision_score(y_val, sgd_preds)\n",
    "ridge_precision = precision_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Precision: {logreg_precision}\")\n",
    "print(f\"Naive Bayes Precision: {naive_bayes_precision}\")\n",
    "print(f\"SGD Classifier Precision: {sgd_precision}\")\n",
    "print(f\"Ridge Classifier Precision: {ridge_precision}\\n\")\n",
    "\n",
    "logreg_recall = recall_score(y_val, logreg_preds)\n",
    "naive_bayes_recall = recall_score(y_val, naive_bayes_preds)\n",
    "sgd_recall = recall_score(y_val, sgd_preds)\n",
    "ridge_recall = recall_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression Recall: {logreg_recall}\")\n",
    "print(f\"Naive Bayes Recall: {naive_bayes_recall}\")\n",
    "print(f\"SGD Classifier Recall: {sgd_recall}\")\n",
    "print(f\"Ridge Classifier Recall: {ridge_recall}\\n\")\n",
    "\n",
    "logreg_f1_score = f1_score(y_val, logreg_preds)\n",
    "naive_bayes_f1_score = f1_score(y_val, naive_bayes_preds)\n",
    "sgd_f1_score = f1_score(y_val, sgd_preds)\n",
    "ridge_f1_score = f1_score(y_val, ridge_preds)\n",
    "print(f\"Logistic Regression F1-Score: {logreg_f1_score}\")\n",
    "print(f\"Naive Bayes F1-Score: {naive_bayes_f1_score}\")\n",
    "print(f\"SGD Classifier F1-Score: {sgd_f1_score}\")\n",
    "print(f\"Ridge Classifier F1-Score: {ridge_f1_score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with RBF Kernel Accuracy: 0.9718\n",
      "SVC with RBF Kernel Precision: 0.9751783740327605\n",
      "SVC with RBF Kernel Recall: 0.9683664304959585\n",
      "SVC with RBF Kernel F1-Score: 0.9717604646505108\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel='rbf')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_preds = svc_model.predict(X_val)\n",
    "\n",
    "svc_accuracy = accuracy_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Accuracy: {svc_accuracy}\")\n",
    "\n",
    "svc_precision = precision_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Precision: {svc_precision}\")\n",
    "\n",
    "svc_recall = recall_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Recall: {svc_recall}\")\n",
    "\n",
    "svc_f1_score = f1_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel F1-Score: {svc_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with linear kernel Accuracy: 0.9683\n",
      "SVC with linear kernel Precision: 0.9716611395839614\n",
      "SVC with linear kernel Recall: 0.964873765093304\n",
      "SVC with linear kernel F1-Score: 0.9682555577808931\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel='linear')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_preds = svc_model.predict(X_val)\n",
    "\n",
    "svc_accuracy = accuracy_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Accuracy: {svc_accuracy}\")\n",
    "\n",
    "svc_precision = precision_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Precision: {svc_precision}\")\n",
    "\n",
    "svc_recall = recall_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Recall: {svc_recall}\")\n",
    "\n",
    "svc_f1_score = f1_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel F1-Score: {svc_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def get_hypernyms(word):\n",
    "    \"\"\"Retrieve up to three levels of all possible hypernyms for a noun.\"\"\"\n",
    "    synsets = wn.synsets(word, pos=wn.NOUN)\n",
    "    hypernyms = []\n",
    "    \n",
    "    if synsets:\n",
    "        first_level_hypernyms = synsets[0].hypernyms()\n",
    "        for hyper in first_level_hypernyms:\n",
    "            hypernyms.append(hyper.lemma_names()[0])\n",
    "            \n",
    "            second_level_hypernyms = hyper.hypernyms()\n",
    "            for higher_hyper in second_level_hypernyms:\n",
    "                hypernyms.append(higher_hyper.lemma_names()[0])\n",
    "                \n",
    "                third_level_hypernyms = higher_hyper.hypernyms()\n",
    "                for highest_hyper in third_level_hypernyms:\n",
    "                    hypernyms.append(highest_hyper.lemma_names()[0])\n",
    "                    \n",
    "    return hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    tokens = []\n",
    "    pos_tokens = []\n",
    "    for i, token in enumerate(doc):\n",
    "        tokens.append(token.text)\n",
    "        pos_tokens.append(token.tag_)\n",
    "        \n",
    "        if token.pos_ == 'NOUN':\n",
    "            tokens.extend(get_hypernyms(token.text))\n",
    "            \n",
    "        if i < len(doc) - 1:\n",
    "            tokens.append(token.text + '_' + doc[i + 1].text)\n",
    "            pos_tokens.append(token.tag_ + '_' + doc[i + 1].tag_)\n",
    "    \n",
    "    return tokens + pos_tokens\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('dataset.csv')\n",
    "\n",
    "train_set, temp_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "test_set, val_set = train_test_split(temp_set, test_size=0.5, random_state=42)\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=10_000, tokenizer=tokenize)\n",
    "X_train = vectorizer.fit_transform(train_set['text'])\n",
    "X_test = vectorizer.transform(test_set['text'])\n",
    "X_val = vectorizer.transform(val_set['text'])\n",
    "y_train = train_set['humor']\n",
    "y_test = test_set['humor']\n",
    "y_val = val_set['humor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.97375\n",
      "Naive Bayes Accuracy: 0.9438\n",
      "SGD Classifier Accuracy: 0.97245\n",
      "Ridge Classifier Accuracy: 0.96975\n",
      "\n",
      "Logistic Regression Precision: 0.9772818657016485\n",
      "Naive Bayes Precision: 0.9276992596865686\n",
      "SGD Classifier Precision: 0.9748295226634577\n",
      "Ridge Classifier Precision: 0.9785525513315715\n",
      "\n",
      "Logistic Regression Recall: 0.9701626584173236\n",
      "Naive Bayes Recall: 0.9628779562917873\n",
      "SGD Classifier Recall: 0.9700628679772478\n",
      "Ridge Classifier Recall: 0.9606825666101187\n",
      "\n",
      "Logistic Regression F1-Score: 0.9737092493364715\n",
      "Naive Bayes F1-Score: 0.9449613162275977\n",
      "SGD Classifier F1-Score: 0.9724403541239435\n",
      "Ridge Classifier F1-Score: 0.9695352233244373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "logreg_model = LogisticRegression(max_iter=10_000, solver='lbfgs')\n",
    "logreg_model.fit(X_train, y_train)\n",
    "naive_bayes_model = MultinomialNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "\n",
    "logreg_preds = logreg_model.predict(X_val)\n",
    "naive_bayes_preds = naive_bayes_model.predict(X_val)\n",
    "\n",
    "logreg_accuracy = accuracy_score(y_val, logreg_preds)\n",
    "naive_bayes_accuracy = accuracy_score(y_val, naive_bayes_preds)\n",
    "print(f\"Logistic Regression Accuracy: {logreg_accuracy}\")\n",
    "print(f\"Naive Bayes Accuracy: {naive_bayes_accuracy}\\n\")\n",
    "\n",
    "logreg_precision = precision_score(y_val, logreg_preds)\n",
    "naive_bayes_precision = precision_score(y_val, naive_bayes_preds)\n",
    "print(f\"Logistic Regression Precision: {logreg_precision}\")\n",
    "print(f\"Naive Bayes Precision: {naive_bayes_precision}\\n\")\n",
    "\n",
    "logreg_recall = recall_score(y_val, logreg_preds)\n",
    "naive_bayes_recall = recall_score(y_val, naive_bayes_preds)\n",
    "print(f\"Logistic Regression Recall: {logreg_recall}\")\n",
    "print(f\"Naive Bayes Recall: {naive_bayes_recall}\\n\")\n",
    "\n",
    "logreg_f1_score = f1_score(y_val, logreg_preds)\n",
    "naive_bayes_f1_score = f1_score(y_val, naive_bayes_preds)\n",
    "print(f\"Logistic Regression F1-Score: {logreg_f1_score}\")\n",
    "print(f\"Naive Bayes F1-Score: {naive_bayes_f1_score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with RBF Kernel Accuracy: 0.9727\n",
      "SVC with RBF Kernel Precision: 0.976082805748166\n",
      "SVC with RBF Kernel Recall: 0.969264544456641\n",
      "SVC with RBF Kernel F1-Score: 0.9726617264169839\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel='rbf')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_preds = svc_model.predict(X_val)\n",
    "\n",
    "svc_accuracy = accuracy_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Accuracy: {svc_accuracy}\")\n",
    "\n",
    "svc_precision = precision_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Precision: {svc_precision}\")\n",
    "\n",
    "svc_recall = recall_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel Recall: {svc_recall}\")\n",
    "\n",
    "svc_f1_score = f1_score(y_val, svc_preds)\n",
    "print(f\"SVC with RBF Kernel F1-Score: {svc_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with linear kernel Accuracy: 0.96905\n",
      "SVC with linear kernel Precision: 0.9711365003006615\n",
      "SVC with linear kernel Recall: 0.9669693643348967\n",
      "SVC with linear kernel F1-Score: 0.9690484524226212\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel='linear')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_preds = svc_model.predict(X_val)\n",
    "\n",
    "svc_accuracy = accuracy_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Accuracy: {svc_accuracy}\")\n",
    "\n",
    "svc_precision = precision_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Precision: {svc_precision}\")\n",
    "\n",
    "svc_recall = recall_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel Recall: {svc_recall}\")\n",
    "\n",
    "svc_f1_score = f1_score(y_val, svc_preds)\n",
    "print(f\"SVC with linear kernel F1-Score: {svc_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Ensemble Accuracy: 0.97245\n",
      "Stacked Precision: 0.9744488977955912\n",
      "Stacked Recall: 0.9704620297375511\n",
      "Stacked F1-Score: 0.9724513774311284\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define base classifiers\n",
    "logreg_model = LogisticRegression(solver='lbfgs', max_iter=1_000)\n",
    "rbf_svc_model = SVC(kernel='rbf', probability=True, max_iter=1_000)\n",
    "linear_svc_model = SVC(kernel='linear', probability=True, max_iter=1_000)\n",
    "\n",
    "# Define final (meta) classifier\n",
    "final_logreg_model = LogisticRegression(solver='lbfgs', max_iter=1_000)\n",
    "\n",
    "# Create the stacking classifier\n",
    "stacking_classifier = StackingClassifier(estimators=[\n",
    "    ('logistic_regression', logreg_model),\n",
    "    ('rbf_support_vector_classifier', rbf_svc_model),\n",
    "    ('linear_support_vector_classifier', linear_svc_model)\n",
    "], final_estimator=final_logreg_model)\n",
    "\n",
    "# Fit the stacking classifier\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the stacking classifier\n",
    "stacked_preds = stacking_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the stacking classifier\n",
    "stacked_accuracy = accuracy_score(y_val, stacked_preds)\n",
    "print(f\"Stacked Ensemble Accuracy: {stacked_accuracy}\")\n",
    "\n",
    "stacked_precision = precision_score(y_val, stacked_preds)\n",
    "print(f\"Stacked Precision: {stacked_precision}\")\n",
    "\n",
    "stacked_recall = recall_score(y_val, stacked_preds)\n",
    "print(f\"Stacked Recall: {stacked_recall}\")\n",
    "\n",
    "stacked_f1_score = f1_score(y_val, stacked_preds)\n",
    "print(f\"Stacked F1-Score: {stacked_f1_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
